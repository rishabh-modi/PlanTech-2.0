#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Apr  7 23:47:28 2019

@author: jonty
"""

# Decision Tree Classification

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Importing the dataset
dataset = pd.read_csv('plantech.csv')
X = dataset.iloc[:, [2, 4]].values
y = dataset.iloc[:, 3].values

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

#Decision Tree Classifier 
'''from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)'''

#  Random Forest Classification to the Training set
'''from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', random_state = 0)
classifier.fit(X_train, y_train)'''

#Naive Bayes Classifier
from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)


# Predicting the Test set results
y_pred = classifier.predict(X_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred)


# plotting graph
'''from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
print('Accuracy of K-NN classifier on training set: {:.2f}'
     .format(knn.score(X_train, y_train)))
print('Accuracy of K-NN classifier on test set: {:.2f}'
     .format(knn.score(X_test, y_test)))

k_range = range(1, 20)
scores = []
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors = k)
    knn.fit(X_train, y_train)
    scores.append(knn.score(X_test, y_test))
plt.figure()
plt.xlabel('k')
plt.ylabel('accuracy')
plt.scatter(k_range, scores)
plt.xticks([0,5,10,15,20])
'''
#----------------------

acidic = ['Blackberry', 'Potato' , 'Apple' , 'Sweet potato', 'Cranberry', 'Carrot' , 'Chervil']
neutral=[ 'Garlic' , 'Artichoke' , 'Arugula' , 'Broccoli rabe', 'Collard', 'Gourd' , 'Sunchoke' , 'Cucumber' , 'Watermelon']
basic=['Peanut','Cauliflower', 'Corn', 'Tomato', 'Chinese cabbage', 'Collard' , 'Spinach' ,' Sunflower', 'Alpine strawberry'  ]



i=1
while i > 0:
    print("enter the value of pH and temperature")
    X1= float(input())
    Y1=float(input())
    P_test = np.array([[ X1,Y1]  ] )
    P_test = sc.transform(P_test)
    p = classifier.predict( P_test )
    print(p)
    if p==1:
        print("\nSlightly Acidic Soil \n Recommended plants/crops are -\n ")
        print(acidic)
    elif p==2:
        print("\nNeutral Soil  \n Recommended plants/crops are -\n ")
        print(neutral)
    elif p==3:
        print("\nSlightly Basic Soil  \n Recommended plants/crops are -\n ")
        print(basic)
    i = i+1
    print(" \n want to continue?  (1/0)")
    i=int(input())


'''from sklearn.model_selection import cross_val_score

model= cross_val_score(classifier,X,y,cv = 10)
plt.plot(model,"p")



from sklearn.model_selection import train_test_split

train_X, val_X, train_y, val_y = train_test_split(X,y,random_state=0)

model = DecisionTreeRegressor()

model.fit(train_X,train_y)

val_predictions = model.predict(val_X)
print(mean_absolute_error(val_y,val_predictions))'''